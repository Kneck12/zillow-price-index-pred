{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85525141",
   "metadata": {},
   "source": [
    "### Intended as a script which generates a .cvs report in one run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6348d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf;\n",
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt;\n",
    "print(tf.__version__);\n",
    "import pandas as pd;\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler;\n",
    "from sklearn.metrics import mean_squared_error;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2132082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 300);\n",
    "pd.set_option('display.max_rows', 300);\n",
    "tf.keras.backend.set_floatx('float64');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69c2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d643a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHS = 72;\n",
    "SPLIT = 60; # 2014-2018: training, 2019: testing.\n",
    "# BATCH_SIZE = 19; # used in NN_v1\n",
    "BATCH_SIZE = 30;\n",
    "WINDOW_SIZE = 1;\n",
    "\n",
    "TEST_LENGTH = MONTHS - SPLIT;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29c1cf",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763b8aac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multi_data = pd.read_csv('../data/zri_acs_bikeshare_merged.csv', index_col = 0);\n",
    "zip_ids = multi_data.index.unique();\n",
    "\n",
    "multi_data.drop([\"City\", \"State\", \"Metro\", \"CountyName\", \"year\", \"month\", \"datetime\"],\\\n",
    "                 axis = 1, inplace = True);\n",
    "\n",
    "multi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36395610",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = ['percent_graduate_deg', 'percent_bachelors', 'percent_associates',\n",
    "            'percent_highschool', 'percent_less_highschool',\n",
    "            'percent_commute_public_transport', 'percent_commute_less_30',\n",
    "            'percent_buildings_less_10_units', 'percent_buildings_10_19_units',\n",
    "            'percent_buildings_20_49_units', 'percent_buildings_50+_units',\n",
    "            'percent_commute_30_to_59', 'percent_commute_60_to_89',\n",
    "            'percent_commute_90_more', 'percent_new_city', 'percent_new_unit',\n",
    "            'percent_units_owner_occupied', 'median_building_age',\n",
    "            'income_per_capita', 'poverty_rate', 'total_pop',\n",
    "            'percent_workforce_unemployed', 'percent_work_from_home', 'median_age',\n",
    "            'percent_female', 'gini_index', 'percent_not_us_citizen',\n",
    "            'bs_total_systems'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_index = [];\n",
    "column_name = list(multi_data.columns);\n",
    "for i in range(len(column_name)):\n",
    "    if column_name[i] in selected: selected_index.append(i);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038c18c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURES = multi_data.shape[1] - 1;\n",
    "FEATURES = len(selected_index);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b92a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in dataset_train:\n",
    "#     print(np.array(x).shape, np.array(y).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b815f",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839569c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.autograph.experimental.do_not_convert\n",
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    series_selected = series[:, [0]+selected_index];\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series_selected); #(43,)\n",
    "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True);\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1)); #(13,43)\n",
    "    dataset = dataset.shuffle(shuffle_buffer)\\\n",
    "                     .map(lambda window: (window[:-1, 1:], window[-1][0]));\n",
    "    dataset = dataset.batch(batch_size).prefetch(1);\n",
    "    return dataset;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5dcf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
    "    plt.plot(time[start:end], series[start:end], format)\n",
    "    plt.xlabel(\"Time Frame\")\n",
    "    plt.ylabel(\"ZRI\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad66377",
   "metadata": {},
   "source": [
    "### Neural network center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a670a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c679c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model(dataset, termination, test = None):\n",
    "    class myCallbacks(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            mse = logs.get(\"mse\");\n",
    "            if(mse < termination):\n",
    "                print(\"\\nGot an mse at {:.4f} in round {} and stopped training\\n\".format(mse, epoch));\n",
    "                self.model.stop_training = True;\n",
    "            \n",
    "    tf.keras.backend.clear_session();\n",
    "    # dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
    "\n",
    "    callback = myCallbacks();\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "#         tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
    "#                           input_shape=[None]),\n",
    "#       tf.keras.layers.Conv1D(filters=32, kernel_size=3,\n",
    "#                           strides=1, padding=\"causal\",\n",
    "#                           activation=\"relu\",\n",
    "#                           input_shape=[None, WINDOW_SIZE, FEATURES+1]),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences=True, input_shape = [None, WINDOW_SIZE, FEATURES])),\n",
    "        #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences=True)),\n",
    "        # tf.keras.layers.SimpleRNN(8, return_sequences=True),\n",
    "        #  tf.keras.layers.SimpleRNN(16, return_sequences=True),\n",
    "        tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "    #   tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1)\n",
    "        # tf.keras.layers.Lambda(lambda x: x * 2.0)\n",
    "    ]);\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=3e-4, momentum=0.9)\n",
    "    model.compile(loss=tf.keras.losses.Huber(),\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=[\"mae\", \"mse\"])\n",
    "\n",
    "    model.build((None,WINDOW_SIZE,FEATURES))\n",
    "    # model.summary()\n",
    "\n",
    "    if not test: history = model.fit(dataset, epochs=500, callbacks = [callback], verbose = 0);\n",
    "    else: history = model.fit(dataset, epochs=500, validation_data=test,\\\n",
    "                              callbacks=[callback], verbose = 0);\n",
    "    return model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017a84b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_forecast(model, series_transformed):\n",
    "    forecast = []\n",
    "    results = []\n",
    "    for time in range(MONTHS - WINDOW_SIZE):\n",
    "        forecast.append(model.predict(series_transformed[np.newaxis, time:time + WINDOW_SIZE, selected_index]))\n",
    "\n",
    "    results = [float(x[-1][0]) for x in forecast];\n",
    "    actual = list(series_transformed[WINDOW_SIZE:, 0]);\n",
    "    \n",
    "    return results, actual; #, pure_forecast;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b91b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.autograph.experimental.do_not_convert\n",
    "def NN_test(ZONE, termination=0, plot=False):\n",
    "    '''\n",
    "    Input: ZONE\n",
    "    Output: the RMSE of a NN model on the predicted train, partially predicted test, and complete predicted test.\n",
    "    '''\n",
    "    # Collection of data\n",
    "    series_frame = multi_data[multi_data.index == ZONE];\n",
    "    # series_frame.sort_values(\"datetime\", ascending = True, inplace = True);\n",
    "    \n",
    "    # Standardization\n",
    "    scaler = StandardScaler();\n",
    "    series_transformed = scaler.fit_transform(series_frame);\n",
    "    \n",
    "    # Train test split\n",
    "    series_train = series_transformed[:SPLIT];\n",
    "    series_test = series_transformed[SPLIT-WINDOW_SIZE:];\n",
    "    \n",
    "    # Window the training set to make input of the NN\n",
    "    dataset_train = windowed_dataset(series_train, WINDOW_SIZE, BATCH_SIZE, 60);\n",
    "    # dataset_test = windowed_dataset(series_test, WINDOW_SIZE, BATCH_SIZE, 60);\n",
    "    \n",
    "    model = NN_model(dataset_train, termination);\n",
    "    \n",
    "    time_train = list(range(SPLIT));\n",
    "    time_test = list(range(SPLIT, MONTHS));\n",
    "    \n",
    "    # Forecasting\n",
    "    # results, actual, pure_forecast = NN_forecast(model, series_transformed);\n",
    "    results, actual = NN_forecast(model, series_transformed);\n",
    "    \n",
    "    # Compute MSE\n",
    "    MSE_train = mean_squared_error(actual[:-TEST_LENGTH], results[:-TEST_LENGTH])**0.5 * scaler.var_[0]**0.5;\n",
    "    MSE_pure = mean_squared_error(actual[-TEST_LENGTH:], results[-TEST_LENGTH:])**0.5 * scaler.var_[0]**0.5;\n",
    "    # MSE_pure = mean_squared_error(actual[-TEST_LENGTH:], pure_forecast[-TEST_LENGTH:])**0.5 * scaler.var_[0]**0.5;\n",
    "    \n",
    "    if plot: # If the plot option is selected, plot the graph.\n",
    "        time_actual = range(WINDOW_SIZE, MONTHS);\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plot_series(time_actual, actual);\n",
    "        plot_series(time_actual, results);\n",
    "        # plot_series(time_test, pure_forecast);\n",
    "        plt.show();\n",
    "\n",
    "    return MSE_train, MSE_pure,\\\n",
    "        np.array(results[-TEST_LENGTH:]) * scaler.var_[0]**0.5 + scaler.mean_[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff307a8",
   "metadata": {},
   "source": [
    "### The script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfafc41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict = {\"zip\":[], \"RMSE_train\":[], \"RMSE_pure\":[], \"forecast\":[]};\n",
    "with tf.device('/cpu:0'):\n",
    "    for ZONE in zip_ids:\n",
    "        %time M_train, M_pure, forecast = NN_test(ZONE, termination=0.005, plot=True);\n",
    "        print(ZONE, M_train, M_pure, forecast);\n",
    "\n",
    "        score_dict[\"zip\"].append(ZONE);\n",
    "        score_dict[\"RMSE_train\"].append(M_train);\n",
    "        # score_dict[\"RMSE_test\"].append(M_test);\n",
    "        score_dict[\"RMSE_pure\"].append(M_pure);\n",
    "        score_dict[\"forecast\"].append(forecast);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d4f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(score_dict[\"RMSE_pure\"]),\\\n",
    "      sum(score_dict[\"RMSE_pure\"])/len(score_dict[\"RMSE_pure\"]));\n",
    "\n",
    "rmse = sum(score_dict[\"RMSE_pure\"])/len(score_dict[\"RMSE_pure\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40678bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(score_dict);\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65472d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('NN_selectedfeatureonly_window_1_overfit_{:.2f}.csv'.format(rmse), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
